{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39909c7a",
   "metadata": {},
   "source": [
    "# SageMaker - Distributed Data Parallelization with Tensorflow - Using Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff4b033",
   "metadata": {},
   "source": [
    "Used in situation where you have to train a model in a really big data set. So we distribute the data among multiple GPUs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81531d73",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166846f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c7cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c62eb",
   "metadata": {},
   "source": [
    "**Training script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ee838",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize train_tensorflow_smdataparallel_mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f31d3f",
   "metadata": {},
   "source": [
    "**SageMaker Estimator**\n",
    "\n",
    " - **`Instance types`** - smdistributed.dataparallel\n",
    " \n",
    " - **`Instance count`** - To get the best performance and the most out of `smdistributed.dataparallel`, you should use at least 2 instances, but you can also use 1 for testing this example.\n",
    " \n",
    " - **`Distribution strategy`** - Note that to use DDP mode, you update the the distribution strategy, and set it to use smdistributed dataparallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1108836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    base_job_name=\"tensorflow2-smdataparallel-mnist\",\n",
    "    #source_dir=\"code\",\n",
    "    entry_point=\"train_tensorflow_smdataparallel_mnist.py\",\n",
    "    role=role,\n",
    "    py_version=\"py37\",\n",
    "    framework_version=\"2.4.1\",\n",
    "    \n",
    "    # For training with multinode distributed training, set this count. Example: 1\n",
    "    instance_count=2,\n",
    "    \n",
    "    # For training with p3dn instance use - ml.p3dn.24xlarge, with p4dn instance use - ml.p4d.24xlarge\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    \n",
    "    # Training using SMDataParallel Distributed Training Framework\n",
    "    distribution={\"smdistributed\": {\"dataparallel\": {\"enabled\": True}}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc95fe7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c6eac9",
   "metadata": {},
   "source": [
    "Now that you have a trained model, you can deploy an endpoint to host the model. After you deploy the endpoint, you can then test it with inference requests. The following cell will store the model_data variable to be used with the inference notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556fcdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = estimator.model_data\n",
    "print(\"Storing {} as model_data\".format(model_data))\n",
    "%store model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9e3fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd68c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5726f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data(path=\"/tmp/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a64aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    data = mnist_images[i].reshape(1, 28, 28, 1)\n",
    "\n",
    "    predict_response = predictor.predict(data)\n",
    "\n",
    "    print(\"========================================\")\n",
    "    label = mnist_labels[i]\n",
    "\n",
    "    predict_label = np.argmax(predict_response[\"predictions\"])\n",
    "\n",
    "    print(\"label is {}\".format(label))\n",
    "    print(\"prediction is {}\".format(predict_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96225796",
   "metadata": {},
   "source": [
    "**Cleanup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f46a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
